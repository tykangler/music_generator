{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate music, I will use the **transformer** model, used by OpenAI in their GPT-2 model. In prior iterations, I had considered using RNNs with the seq2seq model. But after further research, I discovered that the transformer model can achieve better performance and accuracy, with the added benefit of parallelization, albeit at the cost of memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain, islice\n",
    "from functools import cmp_to_key\n",
    "from copy import deepcopy\n",
    "from fractions import Fraction\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitch(note: int):\n",
    "    notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    return f\"{notes[note % 12]}{note // 12 - 1}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Test Score: <br>\n",
    "<img height=800 width=600 src=\"https://imslp.org/images/8/8b/TN-Schumann%2C_Robert_Werke_Breitkopf_Gregg_Serie_7_Band_2_RS_51_Op_13_scan.jpg\"></img> <br>\n",
    "Robert Schumann,Symphonic Etudes Op. 13 (with Posthumous variations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to play music\n",
    "TEST_FILE = f'{DATA_DIR}/maestro-v3.0.0/2018/MIDI-Unprocessed_Recital20_MID--AUDIO_20_R1_2018_wav--4.midi'\n",
    "def play_midi(file_name=TEST_FILE):\n",
    "    os.startfile(os.path.abspath(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_note_on = lambda msg: msg.type == 'note_on' and msg.velocity > 0\n",
    "is_note_off = lambda msg: (msg.type == 'note_on' and msg.velocity == 0) or msg.type == 'note_off'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to iterate over tracks for correct deltatime value (ticks), otherwise deltatime is seconds. This is also faster.\n",
    "def print_messages(track, limit: int=0, *, transnote=None, transvelocity=None, transtime=None):\n",
    "    transnote = transnote or (lambda note: note) \n",
    "    transvelocity = transvelocity or (lambda velocity: velocity)\n",
    "    transtime = transtime or (lambda time: time)\n",
    "    track = islice(track, limit) if limit > 0 else track\n",
    "    for event in track:\n",
    "        if is_note_on(event):\n",
    "            note, velocity, time = transnote(event.note), transvelocity(event.velocity), transtime(event.time)\n",
    "            print(f'note_on channel={event.channel} note={note} velocity={velocity} time={time}')\n",
    "        elif is_note_off(event):\n",
    "            note, velocity, time = transnote(event.note), transvelocity(event.velocity), transtime(event.time)\n",
    "            print(f'note_off channel={event.channel} note={note} time={time}')\n",
    "        else:\n",
    "            print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schumann = mido.MidiFile(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "schumann.ticks_per_beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<meta message track_name name='contestant 20' time=0>\nprogram_change channel=0 program=0 time=0\ncontrol_change channel=0 control=64 value=127 time=0\ncontrol_change channel=0 control=67 value=0 time=0\nnote_on channel=0 note=C#5 velocity=64 time=775\nnote_on channel=0 note=E4 velocity=41 time=41\nnote_on channel=0 note=G#4 velocity=46 time=4\nnote_on channel=0 note=C#2 velocity=39 time=8\nnote_on channel=0 note=C#4 velocity=35 time=9\nnote_on channel=0 note=G#2 velocity=30 time=8\nnote_off channel=0 note=C#5 time=222\nnote_off channel=0 note=G#4 time=45\nnote_off channel=0 note=E4 time=31\nnote_off channel=0 note=C#4 time=113\nnote_on channel=0 note=G#4 velocity=67 time=365\nnote_on channel=0 note=G#3 velocity=45 time=28\nnote_on channel=0 note=E4 velocity=44 time=1\nnote_on channel=0 note=C#4 velocity=44 time=14\nnote_off channel=0 note=G#4 time=252\nnote_off channel=0 note=E4 time=50\n"
     ]
    }
   ],
   "source": [
    "print_messages(schumann.tracks[1], 20, transnote=get_pitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Ticks to Beats\n",
    "\n",
    "Time attribute represents <deltatime\\>. <deltatime\\> is represented as number of ticks before playing the message. The number of ticks per beat is defined in the MThd chunk as <division\\>. (i.e. <division\\> = 96 means 96 ticks per beat). The number of microseconds per beat is defined as $500,000 \\frac{\\mu s}{beat}$, or can be set in the meta message 'set_tempo' in each track.\n",
    "\n",
    "So $time = 288$, $division = 384$, $tempo = 500,000$ equates to $\\frac{500,000}{384} * 288 = 375,000 \\mu s$\n",
    "\n",
    "This is the ticks between the first note_on (C#5) and the corresponding note off\n",
    "\n",
    "This is equivalent to .375 seconds, which is the deltatime value when using `midi.play()` or `iter(midi)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " With $500,000 \\frac{\\mu s}{beat}$, BPM = 120. The denominator of the time signature tells what kind of note (quarter, eighth) is a beat. The numerator tells how many beats are in bar. With a time signature of 4/4, a beat is a quarter note. \n",
    "\n",
    "With $time = 288$, and $division = 384$, $288 \\ \\text{ticks} * \\frac{1}{384} \\frac{beat}{tick} = .75 \\ \\text{beats}$\n",
    "\n",
    "This is equal to $375,000 \\mu s * \\frac{1}{500000} \\frac{beat}{\\mu s} = .75 \\ \\text{beats}$.\n",
    "\n",
    "A time signature of 4 means $time = 288$ is .75 of a quarter note. However, from the image above, the first notes are quarter notes, not fractions of quarter notes, probably because the performance was played with a different BPM in mind (Andante, maybe 90), and not the one given in the midi file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization\n",
    "\n",
    "Quantize notes so that notes will have deltatime corrected to the nearest multiple of $\\epsilon$. A lower $\\epsilon$ means a higher frequency, but also more off-beats. A greater $\\epsilon$ means lower frequency, and more synchronization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEAT_RESOLUTION = 64\n",
    "BEAT = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<meta message track_name name='contestant 20' time=0>\nprogram_change channel=0 program=0 time=0\ncontrol_change channel=0 control=64 value=127 time=0\ncontrol_change channel=0 control=67 value=0 time=0\nnote_on channel=0 note=C#5 velocity=64 time=768\nnote_on channel=0 note=E4 velocity=41 time=48\nnote_on channel=0 note=G#4 velocity=46 time=0\nnote_on channel=0 note=C#2 velocity=39 time=0\nnote_on channel=0 note=C#4 velocity=35 time=0\nnote_on channel=0 note=G#2 velocity=30 time=0\nnote_off channel=0 note=C#5 time=216\nnote_off channel=0 note=G#4 time=48\nnote_off channel=0 note=E4 time=24\nnote_off channel=0 note=C#4 time=120\nnote_on channel=0 note=G#4 velocity=67 time=360\nnote_on channel=0 note=G#3 velocity=45 time=24\nnote_on channel=0 note=E4 velocity=44 time=0\nnote_on channel=0 note=C#4 velocity=44 time=24\nnote_off channel=0 note=G#4 time=264\nnote_off channel=0 note=E4 time=48\n"
     ]
    }
   ],
   "source": [
    "def nearest_tick(ticks, resolution):\n",
    "    temp = ticks + resolution // 2\n",
    "    return int(temp - temp % resolution)\n",
    "\n",
    "def quantize(track, resolution, ticks_per_beat, beat=4, limit: int=0):\n",
    "    tick_resolution = beat * ticks_per_beat / resolution\n",
    "    if limit > 0:\n",
    "        track = islice(track, limit)\n",
    "    return [msg.copy(time=nearest_tick(msg.time, tick_resolution)) \n",
    "            if msg.type == 'note_on' else msg.copy() \n",
    "            for msg in track]\n",
    "\n",
    "quantized = quantize(schumann.tracks[1], resolution=BEAT_RESOLUTION, beat=BEAT, ticks_per_beat=schumann.ticks_per_beat)\n",
    "print_messages(quantized, 20, transnote=get_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "schumann_copy = deepcopy(schumann)\n",
    "schumann_copy.tracks[1] = mido.MidiTrack(quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "schumann_copy.save('schumann.midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Away from Midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class setup\n",
    "class Note:\n",
    "    def __init__(self, pitch, velocity, instrument='piano'):\n",
    "        self.pitch = pitch\n",
    "        self.velocity = velocity\n",
    "        self.instrument = instrument\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.pitch}:{self.velocity}:{self.instrument}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<Note pitch={self.pitch} velocity={self.velocity} instrument={self.instrument}>\"\n",
    "\n",
    "    def __eq__(self):\n",
    "        return self.pitch == other.pitch and self.velocity == other.velocity and self.instrument == other.instrument\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.pitch, self.velocity, self.instrument))\n",
    "\n",
    "class Wait:\n",
    "    def __init__(self, beats):\n",
    "        self.beats = beats\n",
    "\n",
    "    def duration(self):\n",
    "        return self.beats\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"wait:{self.beats}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"<Wait {self.beats}>\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.beats == other.beats\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.beats)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_beats(track, tick_per_beat, limit=0):\n",
    "    if limit > 0:\n",
    "        track = islice(track, limit)\n",
    "    tick_to_beat = lambda tick, tick_per_beat: tick / tick_per_beat \n",
    "    return [(Wait(Fraction(tick_to_beat(msg.time, tick_per_beat)).numerator), Note(get_pitch(msg.note), msg.velocity))\n",
    "            for msg in track if msg.type == 'note_on']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(<Wait 2>, <Note pitch=C#5 velocity=64 instrument=piano>),\n",
       " (<Wait 1/8>, <Note pitch=E4 velocity=41 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=G#4 velocity=46 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=C#2 velocity=39 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=C#4 velocity=35 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=G#2 velocity=30 instrument=piano>),\n",
       " (<Wait 9/16>, <Note pitch=C#5 velocity=0 instrument=piano>),\n",
       " (<Wait 1/8>, <Note pitch=G#4 velocity=0 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=E4 velocity=0 instrument=piano>),\n",
       " (<Wait 5/16>, <Note pitch=C#4 velocity=0 instrument=piano>),\n",
       " (<Wait 15/16>, <Note pitch=G#4 velocity=67 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=G#3 velocity=45 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=E4 velocity=44 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=C#4 velocity=44 instrument=piano>),\n",
       " (<Wait 11/16>, <Note pitch=G#4 velocity=0 instrument=piano>),\n",
       " (<Wait 1/8>, <Note pitch=E4 velocity=0 instrument=piano>),\n",
       " (<Wait 5/16>, <Note pitch=C#4 velocity=0 instrument=piano>),\n",
       " (<Wait 5/16>, <Note pitch=G#3 velocity=0 instrument=piano>),\n",
       " (<Wait 5/8>, <Note pitch=E4 velocity=67 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=E3 velocity=46 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=C#4 velocity=48 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=G#3 velocity=36 instrument=piano>),\n",
       " (<Wait 3/8>, <Note pitch=E4 velocity=0 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=G#3 velocity=0 instrument=piano>),\n",
       " (<Wait 1/8>, <Note pitch=C#4 velocity=0 instrument=piano>),\n",
       " (<Wait 13/16>, <Note pitch=E3 velocity=0 instrument=piano>),\n",
       " (<Wait 5/16>, <Note pitch=C#4 velocity=66 instrument=piano>),\n",
       " (<Wait 1/8>, <Note pitch=G#3 velocity=39 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=E3 velocity=36 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=C#3 velocity=33 instrument=piano>)]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "schumann_seq = to_beats(schumann_copy.tracks[1], schumann_copy.ticks_per_beat)\n",
    "schumann_seq[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last value in each tuple represents the number of beats for that note is played. Because notes were quantized with a 64th note resolution and beats set to quarter notes, each note will have a time that is some multiple of $\\frac{1}{16}$. \n",
    "\n",
    "> When quantizing, each tick value was adjusted so that $$\\text{ticks}' = x * \\frac{\\text{beat} * \\text{ticks_per_beat}}{\\text{resolution}}$$When converting to beats, $\\text{ticks}'$ is divided by ticks_per_beat. $$\\text{beats} = \\frac{\\text{ticks}'}{\\text{ticks_per_beat}} = x * \\frac{\\text{beat} * \\text{ticks_per_beat}}{\\text{resolution} * \\text{ticks_per_beat}} = x * \\frac{\\text{beat}}{\\text{resolution}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEAT_BASE = BEAT / BEAT_RESOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this approach, we will have 16 waits defined in the vocabulary (wait:[1-16]). Waits longer than 1 beat will be recorded as (wait:16, wait:n). However, a constant resolution needs to be set for all songs. Test quantizing a faster song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantizing faster songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "program_change channel=0 program=0 time=0\ncontrol_change channel=0 control=64 value=80 time=0\ncontrol_change channel=0 control=67 value=126 time=0\ncontrol_change channel=0 control=64 value=78 time=896\nnote_on channel=0 note=40 velocity=31 time=64\ncontrol_change channel=0 control=64 value=80 time=7\ncontrol_change channel=0 control=64 value=83 time=21\ncontrol_change channel=0 control=64 value=86 time=17\ncontrol_change channel=0 control=64 value=90 time=20\ncontrol_change channel=0 control=64 value=98 time=39\ncontrol_change channel=0 control=64 value=103 time=16\ncontrol_change channel=0 control=64 value=108 time=21\ncontrol_change channel=0 control=64 value=112 time=17\ncontrol_change channel=0 control=64 value=118 time=37\ncontrol_change channel=0 control=64 value=124 time=38\nnote_off channel=0 note=40 time=40\nnote_on channel=0 note=47 velocity=39 time=0\nnote_off channel=0 note=47 time=101\nnote_on channel=0 note=55 velocity=43 time=85\nnote_off channel=0 note=55 time=94\n"
     ]
    }
   ],
   "source": [
    "TEST_FAST_FILE = f'{DATA_DIR}/maestro-v3.0.0/2004/MIDI-Unprocessed_XP_08_R1_2004_04-06_ORIG_MID--AUDIO_08_R1_2004_05_Track05_wav--2.midi'\n",
    "rachmaninoff = mido.MidiFile(TEST_FAST_FILE)\n",
    "print_messages(rachmaninoff.tracks[1], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "program_change channel=0 program=0 time=0\ncontrol_change channel=0 control=64 value=80 time=0\ncontrol_change channel=0 control=67 value=126 time=0\ncontrol_change channel=0 control=64 value=78 time=896\nnote_on channel=0 note=40 velocity=31 time=60\ncontrol_change channel=0 control=64 value=80 time=7\ncontrol_change channel=0 control=64 value=83 time=21\ncontrol_change channel=0 control=64 value=86 time=17\ncontrol_change channel=0 control=64 value=90 time=20\ncontrol_change channel=0 control=64 value=98 time=39\ncontrol_change channel=0 control=64 value=103 time=16\ncontrol_change channel=0 control=64 value=108 time=21\ncontrol_change channel=0 control=64 value=112 time=17\ncontrol_change channel=0 control=64 value=118 time=37\ncontrol_change channel=0 control=64 value=124 time=38\nnote_off channel=0 note=40 time=30\nnote_on channel=0 note=47 velocity=39 time=0\nnote_off channel=0 note=47 time=90\nnote_on channel=0 note=55 velocity=43 time=90\nnote_off channel=0 note=55 time=90\n"
     ]
    }
   ],
   "source": [
    "rachmaninoff_copy = deepcopy(rachmaninoff)\n",
    "rachmaninoff_copy.tracks[1] = quantize(rachmaninoff_copy.tracks[1], 64, rachmaninoff_copy.ticks_per_beat)\n",
    "print_messages(rachmaninoff_copy.tracks[1], limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rachmaninoff_copy.save('rachmaninoff.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(<Wait 1/8>, <Note pitch=E2 velocity=31 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=E2 velocity=0 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=B2 velocity=39 instrument=piano>),\n",
       " (<Wait 3/16>, <Note pitch=B2 velocity=0 instrument=piano>),\n",
       " (<Wait 3/16>, <Note pitch=G3 velocity=43 instrument=piano>),\n",
       " (<Wait 3/16>, <Note pitch=G3 velocity=0 instrument=piano>),\n",
       " (<Wait 1/8>, <Note pitch=F#3 velocity=38 instrument=piano>),\n",
       " (<Wait 1/8>, <Note pitch=F#3 velocity=0 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=G3 velocity=50 instrument=piano>),\n",
       " (<Wait 3/16>, <Note pitch=G3 velocity=0 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=E3 velocity=45 instrument=piano>),\n",
       " (<Wait 1/8>, <Note pitch=E3 velocity=0 instrument=piano>),\n",
       " (<Wait 1/8>, <Note pitch=G3 velocity=51 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=G3 velocity=0 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=E3 velocity=47 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=D#3 velocity=57 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=E3 velocity=0 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=G3 velocity=58 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=D#3 velocity=0 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=D#3 velocity=53 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=G3 velocity=0 instrument=piano>),\n",
       " (<Wait 3/16>, <Note pitch=D3 velocity=61 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=D#3 velocity=0 instrument=piano>),\n",
       " (<Wait 1/8>, <Note pitch=D3 velocity=0 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=E3 velocity=65 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=E3 velocity=0 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=D3 velocity=65 instrument=piano>),\n",
       " (<Wait 0>, <Note pitch=C#3 velocity=68 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=D3 velocity=0 instrument=piano>),\n",
       " (<Wait 1/16>, <Note pitch=C#3 velocity=0 instrument=piano>)]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "to_beats(rachmaninoff_copy.tracks[1], rachmaninoff_copy.ticks_per_beat)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantizing a faster song works fine. Quantization performance depends on the ticks per beat and the resolution. As long as ticks_per_beat is fairly small (so that tick_resolution is small), then overall resolution will be retained. In practice, we can scale down ticks_per_beat, and <set_tempo\\> by the same amount. Scaling both down will keep $\\frac{\\mu s}{tick}$ the same, so that the absolute timings of each message are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting Waits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_waits(beats_stream):\n",
    "    first = True\n",
    "    for wait, note in beats_stream:\n",
    "        if not first and wait.duration() != 0:\n",
    "            yield wait\n",
    "        first = False\n",
    "        yield note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C#5:64:piano\nwait:1\nE4:41:piano\nG#4:46:piano\nC#2:39:piano\nC#4:35:piano\nG#2:30:piano\nwait:9\nC#5:0:piano\nwait:1\nG#4:0:piano\nwait:1\nE4:0:piano\nwait:5\nC#4:0:piano\nwait:15\nG#4:67:piano\nwait:1\nG#3:45:piano\nE4:44:piano\n"
     ]
    }
   ],
   "source": [
    "for i in islice(with_waits(schumann_seq), 20):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Features\n",
    "\n",
    "Aside from the vocabulary, I will train the model with the following features:\n",
    "\n",
    "- [x] composer\n",
    "- ~~key signature~~ (data not available)\n",
    "- [x] tempo\n",
    "- [x] time period/style\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DATA_DIR}/metadata/composers.json') as composer_file:\n",
    "    composers = json.load(composer_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For composer searching, I will need to clean up the csv file to make sure that composer names match up with the names given in the composers file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(complete_name: str):\n",
    "    result = [composer for composer in composers if composer['complete_name'].lower() == complete_name.lower()]\n",
    "    if len(result) > 0:\n",
    "        return result[0]['epoch']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Late Romantic'"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "epoch('Leoš Janáček')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tempo(it):\n",
    "    DEFAULT_VALUE = 500_000\n",
    "    for x in it:\n",
    "        if x.is_meta and x.type == 'set_tempo':\n",
    "            return x.tempo\n",
    "    return DEFAULT_VALUE\n",
    "\n",
    "def average(it):\n",
    "    sum = 0\n",
    "    len = 0\n",
    "    for x in it:\n",
    "        sum += x\n",
    "        len += 1\n",
    "    return sum / len\n",
    "\n",
    "def scale_exp(x):\n",
    "    return math.exp(x / 500)\n",
    "\n",
    "def average_wait_time(it, ticks_per_beat, tempo):\n",
    "    microseconds_per_tick = tempo / ticks_per_beat\n",
    "    avg_wait = average(x.duration() for x in it if isinstance(x, Wait)) * microseconds_per_tick \n",
    "    return scale_exp(avg_wait)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "schumann:\n35.26091777478518\nrachmaninoff:\n10.67898047974517\n"
     ]
    }
   ],
   "source": [
    "print('schumann:')\n",
    "print(average_wait_time(with_waits(schumann_seq), schumann_copy.ticks_per_beat, find_tempo(schumann_copy.tracks[0])))\n",
    "print('rachmaninoff:')\n",
    "print(average_wait_time(\n",
    "    with_waits(to_beats(rachmaninoff_copy.tracks[1], rachmaninoff_copy.ticks_per_beat)), \n",
    "    rachmaninoff_copy.ticks_per_beat, \n",
    "    find_tempo(rachmaninoff_copy.tracks[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximation I'll use to measure tempo, where MSPT = microseconds per tick:\n",
    "$$\\tau = \\text{exp}(\\frac{MSPT * \\overline{\\text{wait_in_ticks}}}{500})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full vocabulary will consist of 16 waits (or any power of 2 depending on what resolution I go with), and 128 notes, each with 32 volume levels, each with 6 instruments. A total size of 24,592.\n",
    "\n",
    "Volumes will be binned for less noise, and to account for variability in performances.\n",
    "\n",
    "For now I'll just stick with piano, so 88 notes (A0-C8), 32 volumes, 1 instrument, 16 waits. A total size of 2832. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test playback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test playback original\n",
    "play_midi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test playback quantized\n",
    "play_midi('schumann.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test playback original (fast)\n",
    "play_midi(TEST_FAST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test playback quantized (fast)\n",
    "play_midi('rachmaninoff.midi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bard",
   "language": "python",
   "name": "bard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}